# Helm Chart for Pocket Network

{{ template "chart.versionBadge" . }}{{ template "chart.typeBadge" . }}{{ template "chart.appVersionBadge" . }}

Pocket Network is permissionless decentralized physical infrastructure (DePin) protocol that incentivizes and coordinates a network of node operators to provide open data access to anyone. This repository bootstraps a Pocket Network deployment on a Kubernetes cluster using the Helm package manager.

[Overview of Pocket Network](https://pocket.network/)

## TL;DR
```shell
?> git clone git@github.com:eddyzags/pocket-network-helm-chart.git && cd pocket-helm-chart

?> helm install release-1 . -f shannon-values.yaml
```

# Table of Contents

- [Prerequisites](#prerequisites)
- [Installing the Chart](#installing-the-chart)
- [Configuration and Installation Details](#configuration-and-installation-details)
  - [Customizing relayminer and fullnode using configuration](#customizing-relayminer-and-fullnode-using-configuration)
  - [Provisionning keys](#provisionning-keys)
  - [Resources and limits](#resources-and-limits)
  - [Fullnode persistence](#fullnode-persistence)
    - [Adjust permissions of persistent volume mountpoint](#adjust-permissions-of-persistent-volume-mountpoint)
  - [Prometheus metrics](#prometheus-metrics)
  - [Accessing Pocket Network services from outside the cluster](#accessing-pocket-network-services-from-outside-the-cluster)
  - [Deploy fullnode with Cosmosvisor](#deploy-fullnode-with-cosmosvisor)
- [Parameters](#parameters)

## Prerequisites
* Kubernetes 1.23+
* Helm 3.9.0+
* Provisionning keys for Pocket Network Kubernetes Pods (e.g fullnode and relayminer)

## Installing the Chart

To install the chart with name `my-release`
```
?> git clone git@github.com:eddyzags/pocket-network-helm-chart.git && cd pocket-helm-chart

?> helm install fullnode .  -f shannon-values.yaml
```
> Note: You must specify the value in yaml file. This is an example with the values related to Shannon protocol.

This command deploy a fullnode with default values.

## Configuration and installation details

### Customizing relayminer and fullnode using configuration

### Fullnode

A fullnode requires a more in-depth setup to configure Tendermint (consensus engine), the P2P network, the RPC servers, and the consensus parameters. Additionally, it requires the application-specific settings related to staking, gas, API, block prunning. This chart provides multiple solutions to provision these configuration files.

* Option A) Define the configuration file as input values while installing the chart. This can be useful if you already have these configuration files in your local machine.

```
?> helm install release-1 . -f shannon-values.yaml --set-file 'shannon.fullnode.cometbft.config=config.toml' --set-file 'shannon.fullnode.cometbft.app=app.toml' --set-file 'shannon.fullnode.cometbft.client=client.toml'
```

* Option B) Use Kubernetes `ConfigMap` to mount configuration files. This can be useful if you want to use a single configuration for all your fullnode for example.

```
# values.yaml

shannon:
  fullnode:
    enabled: true
    cometbft:
      volumes:
        enabled: true
        type: ConfigMap
        config:
          key:
            name: pocket-network-release-1-shannon
            configKeyName: config.toml
            clientKeyName: client.toml
            appKeyName: app.toml
```

* Option C) Use default value define in the `shannon-values.yaml`. It can be useful for testing purposes.

```
?> helm install my-release . --f shannon-values.yaml
```

#### Relayminer

A relayminer configuration typically involves service endpoint you want to send relays to, a pocket rpc node (you can use the fullnode of this chart for example) to sign each processed relays. This configuration can be tailored to your need by providing a `shannon.relayminer.config` in the Helm values. This a personalized configuration for the relayminer:

```
# values.yaml

shannon:
  relayminer:
    enabled: true
    config:
      default_signing_key_names: [supplier1]
      smt_store_path: /.pocket/smt
      pocket_node:
        query_node_rpc_url: tcp://node:26657
        query_node_grpc_url: tcp://node:9090
        tx_node_rpc_url: tcp://node:26657
      suppliers:
      - service_id: anvil
        service_config:
          backend_url: http://anvil:8547/
          publicly_exposed_endpoints:
            - relayminer1
        listen_url: http://0.0.0.0:8545
      metrics:
        enabled: true
        addr: :9090
      pprof:
        enabled: true
        addr: localhost:6060
      ping:
        enabled: true
        addr: localhost:8081
```

### Provisionning keys

This section refers to the key management capabilities this chart offers to configure each instance of the Pocket Network which are essential for signing transactions and managing accounts on a Cosmos-based blockchain. 

#### Relayminer

In Pocket Network, all relayminers needs one or multiple signing key to sign each relays he serves with a private key. Therefore, each key name listed in `shannon.relayminer.config.default_signing_key_names` must be present in the keyring backend used to start the Relayminer instances.
This example demonstrates how to provision a key through Kubernetes secret while using a `keyring-backend=test`:

```
# values.yaml

shannon:
  relayminer:
    enabled: true
    secret:
      type: Secret
      key:
        name: pocket-network-release-1-shannon-relayminer
        keyName: supplier1.info
```

> Note: Every signing key names (`shannon.relayminer.config.default_signing_key_names`) must have a corresponding secret key. Therefore, if I have `shannon.relayminer.config.default_signing_key_names=["relayminer"]`, we must provide a secret with `shannon.relayminer.secret.key.keyName="relayminer.info"` (name must be the same without file extension .info)

#### Fullnode

A Shannon Fullnode requires two important key files. The node key as a unique identifier for your node on the P2P network used solely for identifying and authenticating with others, and the validator private key used for signing consensus messages (e.g. block proposals, votes). This example demonstrates how to provision a node and validator private key for a fullnode:

```
# values.yaml

shannon:
  fullnode:
    enabled: true
    combetbft:
      secret:
        type: Secret
        key:
          name: pocket-network-release-1-shannon
          nodeKeyName: node_key.json
          privValidatorKeyName: priv_validator_key.json
```

### Resources and limits

Pocket Network charts allow setting resource requests and limits for every containers inside the chart deployment. There are inside the `resources` values.
To make this resource and limit definition easier to define, this chart contains a `resources.preset` attribute that sets the `resources.limits` and `resources.requests`. These presets are recommended by the community, but you can define your own.

```
# values.yaml

shannon:
  fullnode:
    enabled: true
    resources:
      preset:
        enabled: false
        name: medium
      requests:
        cpu: 2000m
        memory: 2Gi
      limits:
        cpu: 3000m
        memory: 3Gi
```

> Note: If the preset is enabled, the templating engine will ignore the `shannon.fullnode.resources.requests` and `shannon.fullnode.resources.limits` fields.

### Fullnode Persistence

The fullnode software stores the various runtime data such as state information, configuration files, and other crucial data required for the operation of a node inside the volume mount of the container. This chart provides multiple options to manage this volume for the fullnode

* Option A) Use an empty data directory to start the fullnode on a clean slate. This can be useful for test purposes.

```
# values.yaml

shannon:
  fullnode:
    enabled: true
    storage:
      data:
      enabled: false
```

> Note: This options doesn't persistent the data across deployments. In other words, if the Kubernetes Pod restarts, you will loose all your data.

* Option B) Use a Persistent Volume Claim (PVC) to start the fullnode on a clean slate, or an existing slate. Persistent Volume Claims are used to keep data across deployments. This integration is known to work in Google Cloud Platform (GCP), Amazon Web services (AWS), on-premise, and minikube.

```
# values.yaml

shannon:
  fullnode:
    enabled: true
    storage:
      data:
      enabled: true
      volumeClaimTemplate:
        annotations: {}
        accessModes: ["ReadWriteOnce"]
        storageClassName: ""
        selector:
          matchLabels:
            app.pocket.network: pocket-network-pv-shannon
        volumeMode: Filesystem
        resources:
          requests:
            storage: 1000Gi
          limits:
            storage: 1500Gi
```

#### Adjust permissions of persistent volume mountpoint

As the image run as non-root by default, it is necessary to adjust the ownership of the persistent volume so that the container process can write data into it. Follow this link to know which UID and GID is configured by default for [ghcr.io/pokt-network/pocketd](https://github.com/pokt-network/poktroll/blob/3ba0390f66636f16441bbf53950ae4c8990479ca/Dockerfile.release#L11-L12)

### Prometheus metrics

The applications can be integrated with Prometheus by defining a custom resource to automatically scrapped the metrics.

> Note: A functional installation of Prometheus Operator with the necessary permissions to access required resources in the target namespace is essential for this integration to work.

#### Relayminer

For the relayminer, setting `shannon.relayminer.config.metrics.enabled` and `shannon.relayminer.prometheus.serviceMonitor.enabled` to `true` will send the application metrics to Prometheus. `shannon.relayminer.config.metrics.enabled` exposes a Prometheus endpoint to consume applications metrics. And `shannon.relayminer.prometheus.serviceMonitor.enabled` creates a `ServiceMonitor` custom resource that points to the `shannon.relayminer.config.metrics.addr`.

```
# values.yaml

shannon:
  relayminer:
    enabled: true
    config:
      metrics:
        enabled: true
        addr: :9090
    prometheus:
      serviceMonitor:
        enabled: true
```

#### Fullnode

For the fullnode, the CosmosSDK `shannon.fullnode.cometbft.config` configuration file gives us the ability to activate a prometheus collector connections at a specific endpoint. Every metrics in this [CosmosBFT - Metrics](https://docs.cometbft.com/main/explanation/core/metrics) documentation will be available to you.
When the `prometheus` option is enabled in `config.toml` and an address and port are specified using `prometheus_listen_addr`, this chart automatically adds the port to a Kubernetes Service and creates a corresponding `ServiceMonitor` pointing to it.

An example is available in the default values - [see here](https://github.com/eddyzags/pocket-network-helm-chart/blob/6aca94ba72ee7a792bf71110a399c50596119ce0/shannon-values.yaml#L861-L881)

### Accessing Pocket Network Services from outside the cluster

This section outlines how to configure external access, allowing users to interact with your service through the Pocket Network's decentralized infrastructure.

#### Relayminer

The Relayminer exposes servers, each hosting one or more services that a supplier has staked on-chain to the Pocket Network. This chart provides the ability to expose those servers using a Kubernetes Ingress custom resource. The following example demonstrates how to define external access to two servers for the Relayminer:

```
# values.yaml

shannon:
  relayminer:
    enabled: true
    config:
      suppliers:
      - service_id: anvil
        service_config:
          backend_url: http://anvil:8547/
          publicly_exposed_endpoints:
            - servera.relayminer.example.com
        listen_url: http://0.0.0.0:8545
      - service_id: ollama
        service_config:
          backend_url: http://ollama:8080/
          publicly_exposed_endpoints:
            - serverb.relayminer.example.com
        listen_url: http://0.0.0.0:8546
    ingress:
      enabled: true
      className: ""
      annotations: {}
      tls: []
      hosts:
      - host: servera.relayminer.example.com
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: relayminer-service
                port:
                  number: 8545
      - host: serverb.relayminer.example.com
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: relayminer-service
                port:
                  number: 8546
```

> Note: For Kubernetes to route traffic properly, the value of `shannon.relayminer.ingress.hosts[].paths[].backend.service.port.number` must match the port specified in `shannon.relayminer.config.suppliers[].listen_url`.

This example demonstrates how to define an external access with a certificate request using cert-manager.

```
shannon:
  relayminer:
    enabled: true
    config:
      suppliers:
      - service_id: anvil
        service_config:
          backend_url: http://anvil:8547/
          publicly_exposed_endpoints:
            - servera.relayminer.example.com
        listen_url: http://0.0.0.0:8545
      - service_id: ollama
        service_config:
          backend_url: http://ollama:8080/
          publicly_exposed_endpoints:
            - serverb.relayminer.example.com
        listen_url: http://0.0.0.0:8546
    ingress:
      # activates the definition of an ingress resource.
      enabled: true
      className: ""
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-staging
        cert-manager.io/acme-challenge-type: "http01"
        cert-manager.io/acme-http01-edit-in-place: "true"
        cert-manager.io/issue-temporary-certificate: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/private-key-algorithm: rsa
        cert-manager.io/private-key-encoding: PKCSI
        cert-manager.io/private-key-size: "2048"
      tls:
      - hosts:
          - servera.relayminer.example.com
        secretName: pocket-network-shannon-relayminer-servera
      - hosts:
          - serverb.relayminer.example.com
        secretName: pocket-network-shannon-relayminer-serverb
      hosts:
      - host: servera.relayminer.example.com
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: relayminer-service
                port:
                  number: 8545
      - host: serverb.relayminer.example.com
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: relayminer-service
                port:
                  number: 8546
```

#### Fullnode

The fullnode can expose one public-facing port to allow other nodes to connect, query its status, and broadcast transactions. This chart allows configuration of an external service using Kubernetes NodePort, exposing the port on each nodeâ€™s IP at a static port.

```
shannon:
  fullnode:
    service:
      local:
        type: ClusterIP
      external:
        enabled: true
        type: NodePort
        p2p:
          nodePort: 26656
```

> Note: the `shannon.fullnode.service.local` field creates a Kubernetes Service resource for internal service communication inside the Kubernetes cluster.

### Deploy fullnode with Cosmosvisor

Cosmovisor is a daemon process for Cosmos SDK-based application binaries. It monitors the governance module for on-chain upgrade proposals and automatically manages chain upgrades for pocketd. By activating this deployment mode, the pocketd process will executed as a sub-process of the cosmosvisor. This chart provides the ability to configure Cosmovisor for a full node setup.

```
# values.yaml

shannon:
  fullnode:
    enabled: true
    cosmosvisor:
      enabled: true
      daemon:
        name: "pocketd"
        allowDownloadBinaries: true
        restartAfterUpgrade: true
        unsafeSkipBackup: false
        pollInterval: 300ms
        preupgradeMaxRetries: 0
```

> Note: For more informations about what the cosmosvisor daemon does, [read this documentation](https://docs.cosmos.network/v0.45/run-node/cosmovisor.html)

## Parameters

{{ define "chart.valueDefaultColumnRender" }}
{{- $defaultValue := (default .Default .AutoDefault)  -}}
{{- $notationType := .NotationType }}
{{- if (and (hasPrefix "`" $defaultValue) (hasSuffix "`" $defaultValue) ) -}}
{{- $defaultValue = (toPrettyJson (fromJson (trimAll "`" (default .Default .AutoDefault) ) ) ) -}}
{{- $notationType = "json" }}
{{- end -}}
{{- if (eq $notationType "tpl" ) }}
<pre lang="{{ $notationType }}">
{{ .Key }}: |
  {{ $defaultValue  }}
</pre>
{{- else if (eq $notationType "toml") }}
<a href="./shannon-values.yaml">see example in shannon-values.yaml</a>
{{- else if (eq $notationType "email") }}
<a href="mailto:{{ $defaultValue }}" style="color: green;">"{{ $defaultValue }}"</a>
{{- else }}
<pre lang="{{ $notationType }}">
{{ $defaultValue }}
</pre>
{{- end }}
{{ end }}

{{ define "chart.typeColumnRender" }}
{{- if (eq .Type "string/email") }}
<a href="#stringemail" title="{{- template "chart.valuetypes.email" -}}">{{.Type}}</a>
{{- else if (eq .Type "k8s/storage/persistent-volume/access-modes" )}}
<a target="_blank" 
   href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes"
   >{{- .Type }}</a>
{{- else }}
{{ .Type }}
{{- end }}
{{ end }}

{{ define "chart.valuesTableHtml" }}
<table height="400px" >
	<thead>
		<th>Key</th>
		<th>Type</th>
		<th>Default</th>
		<th>Description</th>
	</thead>
	<tbody>
	{{- range .Values }}
		<tr>
			<td id="{{ .Key | replace "." "--" }}">{{ .Key }}</td>
			<td>{{- template "chart.typeColumnRender" . -}}</td>
			<td>
				<div style="max-width: 300px;">{{ template "chart.valueDefaultColumnRender" . }}</div>
			</td>
			<td>{{ if .Description }}{{ .Description }}{{ else }}{{ .AutoDescription }}{{ end }}</td>
		</tr>
	{{- end }}
	</tbody>
</table>
{{ end }}

{{ template "chart.valuesSectionHtml" . }}